{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DeepCausalMMM Quick Start Guide\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adityapt/deepcausalmmm/blob/main/examples/quickstart.ipynb)\n",
        "[![PyPI](https://badge.fury.io/py/deepcausalmmm.svg)](https://pypi.org/project/deepcausalmmm/)\n",
        "\n",
        "Welcome! This notebook will walk you through using **DeepCausalMMM** for Marketing Mix Modeling.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "1. \ud83d\udce6 Install DeepCausalMMM\n",
        "2. \ud83d\udcca Generate synthetic MMM data\n",
        "3. \ud83d\ude80 Train a model\n",
        "4. \ud83d\udcc8 Analyze results\n",
        "5. \ud83d\udcc9 Fit response curves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install deepcausalmmm -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import deepcausalmmm\n",
        "\n",
        "from deepcausalmmm import DeepCausalMMM\n",
        "from deepcausalmmm.core import get_default_config\n",
        "from deepcausalmmm.core.trainer import ModelTrainer\n",
        "from deepcausalmmm.core.data import UnifiedDataPipeline\n",
        "from deepcausalmmm.utils.data_generator import generate_synthetic_mmm_data\n",
        "from deepcausalmmm.postprocess import ResponseCurveFit\n",
        "\n",
        "print(f\"\u2705 DeepCausalMMM v{deepcausalmmm.__version__} loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Generate Synthetic Data\n",
        "\n",
        "For this demo, we'll generate synthetic MMM data with:\n",
        "- 10 regions (DMAs)\n",
        "- 52 weeks\n",
        "- 5 media channels\n",
        "- 3 control variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate data\n",
        "df = generate_synthetic_mmm_data(\n",
        "    n_regions=10,\n",
        "    n_weeks=52,\n",
        "    n_media=5,\n",
        "    n_controls=3,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(f\"\ud83d\udcca Data shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Configure Model\n",
        "\n",
        "Get default config and customize for quick demo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = get_default_config()\n",
        "\n",
        "# Reduce epochs for quick demo\n",
        "config['n_epochs'] = 200  # Use 2500+ for production\n",
        "config['learning_rate'] = 0.01\n",
        "\n",
        "print(\"\u2699\ufe0f Configuration:\")\n",
        "print(f\"  Epochs: {config['n_epochs']}\")\n",
        "print(f\"  Learning Rate: {config['learning_rate']}\")\n",
        "print(f\"  Hidden Dim: {config['hidden_dim']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize pipeline\n",
        "pipeline = UnifiedDataPipeline(config)\n",
        "\n",
        "# Process data\n",
        "processed_data = pipeline.fit_transform(df)\n",
        "\n",
        "print(\"\u2705 Data processed!\")\n",
        "print(f\"Training: {processed_data['train_tensors']['X_media'].shape}\")\n",
        "print(f\"Holdout: {processed_data['holdout_tensors']['X_media'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train\n",
        "trainer = ModelTrainer(config)\n",
        "model, results = trainer.train(processed_data)\n",
        "\n",
        "print(\"\\n\u2705 Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: View Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\ud83d\udcca Performance Metrics:\\n\")\n",
        "print(f\"Training R\u00b2: {results['train_r2']:.4f}\")\n",
        "print(f\"Holdout R\u00b2: {results['holdout_r2']:.4f}\")\n",
        "print(f\"\\nTraining RMSE: {results['train_rmse']:.2f}\")\n",
        "print(f\"Holdout RMSE: {results['holdout_rmse']:.2f}\")\n",
        "\n",
        "gap = abs(results['train_r2'] - results['holdout_r2']) / results['train_r2'] * 100\n",
        "print(f\"\\nPerformance Gap: {gap:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Get Contributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions and contributions\n",
        "postprocess = pipeline.predict_and_postprocess(model, split='holdout')\n",
        "\n",
        "predictions = postprocess['predictions']\n",
        "media_contrib = postprocess['media_contributions']\n",
        "\n",
        "print(f\"Predictions: {predictions.shape}\")\n",
        "print(f\"Media contributions: {media_contrib.shape}\")\n",
        "print(f\"\\nTotal predicted: {predictions.sum():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Analyze Channels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Channel contributions\n",
        "channel_totals = media_contrib.sum(axis=(0, 1))\n",
        "channels = [f\"Channel_{i+1}\" for i in range(len(channel_totals))]\n",
        "\n",
        "contrib_df = pd.DataFrame({\n",
        "    'Channel': channels,\n",
        "    'Contribution': channel_totals,\n",
        "    'Percentage': channel_totals / channel_totals.sum() * 100\n",
        "}).sort_values('Contribution', ascending=False)\n",
        "\n",
        "print(\"\ud83d\udcca Channel Impact:\\n\")\n",
        "print(contrib_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Response Curves\n",
        "\n",
        "Fit Hill saturation curves to understand diminishing returns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for top channel\n",
        "top_channel_idx = channel_totals.argmax()\n",
        "top_channel = channels[top_channel_idx]\n",
        "\n",
        "# Get impressions from original data\n",
        "impressions_col = [c for c in df.columns if 'media' in c.lower()][top_channel_idx]\n",
        "impressions = df[impressions_col].values\n",
        "\n",
        "# Get contributions\n",
        "contributions = media_contrib[:, :, top_channel_idx].flatten()[:len(impressions)]\n",
        "\n",
        "# Create curve data\n",
        "curve_data = pd.DataFrame({\n",
        "    'week_monday': pd.date_range('2023-01-01', periods=len(impressions), freq='W'),\n",
        "    'impressions': impressions,\n",
        "    'spend': impressions * 0.5,\n",
        "    'predicted': contributions\n",
        "})\n",
        "\n",
        "# Fit curve\n",
        "fitter = ResponseCurveFit(data=curve_data, model_level='Overall')\n",
        "fitter.fit(\n",
        "    x_label='Impressions',\n",
        "    y_label='Contributions',\n",
        "    title=f'Response Curve: {top_channel}',\n",
        "    generate_figure=True,\n",
        "    save_figure=True,\n",
        "    output_path='response_curve.html'\n",
        ")\n",
        "\n",
        "print(f\"\\n\ufffd\ufffd Response Curve for {top_channel}:\")\n",
        "print(f\"  Slope: {fitter.slope:.3f}\")\n",
        "print(f\"  Half-Saturation: {fitter.saturation:,.0f}\")\n",
        "print(f\"  R\u00b2: {fitter.r_2:.3f}\")\n",
        "print(f\"\\n\ud83d\udcbe Saved to: response_curve.html\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udf89 Congratulations!\n",
        "\n",
        "You've successfully:\n",
        "- \u2705 Installed DeepCausalMMM\n",
        "- \u2705 Trained a model\n",
        "- \u2705 Analyzed channel contributions\n",
        "- \u2705 Fitted response curves\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "### \ud83d\udcda Learn More:\n",
        "- [Documentation](https://deepcausalmmm.readthedocs.io/)\n",
        "- [API Reference](https://deepcausalmmm.readthedocs.io/en/latest/api/)\n",
        "- [GitHub](https://github.com/adityapt/deepcausalmmm)\n",
        "\n",
        "### \ud83d\udd27 Advanced Features:\n",
        "- Run comprehensive dashboard\n",
        "- Explore DAG causal discovery\n",
        "- Multi-region analysis\n",
        "- Hyperparameter optimization\n",
        "\n",
        "### \ud83d\udcd6 Citation:\n",
        "```bibtex\n",
        "@software{Puttaparthi_Tirumala_DeepCausalMMM_2025,\n",
        "  author = {Puttaparthi Tirumala, Aditya},\n",
        "  doi = {10.5281/zenodo.17274024},\n",
        "  title = {{DeepCausalMMM}},\n",
        "  url = {https://github.com/adityapt/deepcausalmmm},\n",
        "  version = {1.0.17},\n",
        "  year = {2025}\n",
        "}\n",
        "```\n",
        "\n",
        "**Happy Modeling! \ud83d\ude80**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}